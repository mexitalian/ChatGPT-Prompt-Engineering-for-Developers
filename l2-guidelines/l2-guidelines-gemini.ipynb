{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebe2e9d-685d-4ea3-ab7c-9589caaabff5",
   "metadata": {},
   "source": [
    "# Guidelines for Prompting\n",
    "In this lesson, you'll practice two prompting principles and their related tactics in order to write effective prompts for large language models.\n",
    "\n",
    "## Setup\n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bab499-9a50-4bd0-a622-1c914c6ccc29",
   "metadata": {},
   "source": [
    "In this course, we've provided some code that loads the OpenAI API key for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acefa8-f8f1-4ef8-932e-9bcefa142666",
   "metadata": {},
   "source": [
    "#### helper function\n",
    "Throughout this course, we will use OpenAI's `gpt-3.5-turbo` model and the [chat completions endpoint](https://platform.openai.com/docs/guides/chat). \n",
    "\n",
    "This helper function will make it easier to use prompts and look at the generated outputs.  \n",
    "**Note**: In June 2023, OpenAI updated gpt-3.5-turbo. The results you see in the notebook may be slightly different than those in the video. Some of the prompts have also been slightly modified to product the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dff174",
   "metadata": {
    "height": 164,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key  = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Configure with your API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Pick a Gemini model (text-only for now)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62298e-2181-4e73-bb40-77e20c655231",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like:\n",
    "    - \\`\\`\\`\n",
    "    - \"\"\"\n",
    "    - < >\n",
    "    - `<tag> </tag>`\n",
    "    - `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87121316",
   "metadata": {
    "height": 336,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve desired and accurate AI model outputs, it is crucial to provide clear, specific, and often detailed instructions rather than just short ones, as this guides the model effectively.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by\n",
    "providing instructions that are as clear and\n",
    "specific as you can possibly make them.\n",
    "This will guide the model towards the desired output,\n",
    "and reduce the chances of receiving irrelevant\n",
    "or incorrect responses. Don't confuse writing a\n",
    "clear prompt with writing a short prompt.\n",
    "In many cases, longer prompts provide more clarity\n",
    "and context for the model, which can lead to\n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks\n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "# Make the Gemini call\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2798f3d-7618-4ac5-a6b2-3c69c537903d",
   "metadata": {},
   "source": [
    "#### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b50bbbd",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"book_id\": \"BK001\",\n",
      "    \"title\": \"The Chronos Curator\",\n",
      "    \"author\": \"Dr. Aris Thorne\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"BK002\",\n",
      "    \"title\": \"Whispers in the Silent Grove\",\n",
      "    \"author\": \"Eleanor Vance\",\n",
      "    \"genre\": \"Psychological Thriller\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"BK003\",\n",
      "    \"title\": \"Aetherbloom's Lament\",\n",
      "    \"author\": \"Lila Sterling\",\n",
      "    \"genre\": \"Fantasy Romance\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\\n",
    "with their authors and genres. \\\n",
    "Provide them in JSON format with the following keys: \\\n",
    "book_id, title, author, genre. \\\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a71c4f-b1f1-4d67-ad5a-e49fc1e3147d",
   "metadata": {},
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0ae612e",
   "metadata": {
    "height": 506,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 1:\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Pour the hot water over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - If you like, add some sugar or milk to taste.\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some\n",
    "water boiling. While that's happening,\n",
    "grab a cup and put a tea bag in it. Once the water is\n",
    "hot enough, just pour it over the tea bag.\n",
    "Let it sit for a bit so the tea can steep. After a\n",
    "few minutes, take out the tea bag. If you\n",
    "like, you can add some sugar or milk to taste.\n",
    "And that's it! You've got yourself a delicious\n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Completion for Text 1:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df51c5b-a9f8-4259-b5b0-3d47564138ef",
   "metadata": {},
   "source": [
    "<mark>Initial reflections on differences on the model is that Gemini 2.5-flash is more verbose, it leaves explicit instructions in place when creating a list of steps. Example here leave in time measures and colloquial terms \"sit for a bit\".</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76b6cc59",
   "metadata": {
    "height": 506,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for Text 2:\n",
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "The sun is shining brightly today, and the birds are\n",
    "singing. It's a beautiful day to go for a\n",
    "walk in the park. The flowers are blooming, and the\n",
    "trees are swaying gently in the breeze. People\n",
    "are out and about, enjoying the lovely weather.\n",
    "Some are having picnics, while others are playing\n",
    "games or simply relaxing on the grass. It's a\n",
    "perfect day to spend time outdoors and appreciate the\n",
    "beauty of nature.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(\"Completion for Text 2:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5866b8-d8c7-4e19-93db-401315f64954",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ce1540",
   "metadata": {
    "height": 251,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: The scent of woodsmoke, that can evoke both cozy warmth and the chill of departing summer;\n",
      "the harmony, that binds together both the soaring major and the melancholic minor;\n",
      "the bittersweet tale, that brings forth both a joyous memory and a quiet regret.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest\n",
    "valley flows from a modest spring; the\n",
    "grandest symphony originates from a single note;\n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about ambivelance.\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f68928-8488-496c-8d6c-eb8c6293f25a",
   "metadata": {},
   "source": [
    "<mark>It was better at waxing poetic within the few-shot prompting.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7a8ee-1a2d-415d-8c10-500ecff24b10",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7d6860",
   "metadata": {
    "height": 506,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion for prompt 1:\n",
      "Jack and Jill, siblings on a quest for water, tumbled down a hill but, though bruised, their adventurous spirits remained undimmed.\n",
      "\n",
      "Jack et Jill, frère et sœur partis chercher de l'eau, ont dégringolé une colline mais, bien que contusionnés, leur esprit d'aventure est resté intact.\n",
      "\n",
      "Jack\n",
      "Jill\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"french_summary\": \"Jack et Jill, frère et sœur partis chercher de l'eau, ont dégringolé une colline mais, bien que contusionnés, leur esprit d'aventure est resté intact.\",\n",
      "  \"num_names\": 2\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on\n",
    "a quest to fetch water from a hilltop\n",
    "well. As they climbed, singing joyfully, misfortune\n",
    "struck—Jack tripped on a stone and tumbled\n",
    "down the hill, with Jill following suit. \n",
    "Though slightly battered, the pair returned home to\n",
    "comforting embraces. Despite the mishap,\n",
    "their adventurous spirits remained undimmed, and they\n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple\n",
    "backticks with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the following\n",
    "keys: french_summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt_1)\n",
    "print(\"Completion for prompt 1:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb1dcf-95f5-4ee1-8c25-8b2abd5f0f0d",
   "metadata": {},
   "source": [
    "#### Ask for output in a specified format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4222cc",
   "metadata": {
    "height": 370,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completion for prompt 2:\n",
      "Text: <\n",
      "In a charming village, siblings Jack and Jill set out on\n",
      "a quest to fetch water from a hilltop\n",
      "well. As they climbed, singing joyfully, misfortune\n",
      "struck—Jack tripped on a stone and tumbled\n",
      "down the hill, with Jill following suit. \n",
      "Though slightly battered, the pair returned home to\n",
      "comforting embraces. Despite the mishap,\n",
      "their adventurous spirits remained undimmed, and they\n",
      "continued exploring with delight.\n",
      ">\n",
      "Summary: Siblings Jack and Jill tumbled down a hill while fetching water but remained adventurous despite their mishap.\n",
      "Translation: Les frères et sœurs Jack et Jill sont tombés d'une colline en allant chercher de l'eau, mais sont restés aventureux malgré leur mésaventure.\n",
      "Names: Jack, Jill\n",
      "Output JSON: {\"french_summary\": \"Les frères et sœurs Jack et Jill sont tombés d'une colline en allant chercher de l'eau, mais sont restés aventureux malgré leur mésaventure.\", \"num_names\": 2}\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "4 - Output a json object that contains the \n",
    "  following keys: french_summary, num_names.\n",
    "\n",
    "Use the following format:\n",
    "Text: <text to summarize>\n",
    "Summary: <summary>\n",
    "Translation: <summary translation>\n",
    "Names: <list of names in summary>\n",
    "Output JSON: <json with summary and num_names>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt_2)\n",
    "print(\"\\nCompletion for prompt 2:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec80fdb-92db-48f6-8f1d-b03c26385bad",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5cc985",
   "metadata": {
    "height": 421,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The student's solution is **incorrect**.\n",
      "\n",
      "Here's a breakdown of the error:\n",
      "\n",
      "1.  **Land cost:** Correct (100x)\n",
      "2.  **Solar panel cost:** Correct (250x)\n",
      "3.  **Maintenance cost:** This is where the error occurs.\n",
      "    *   The problem states: \"flat $100k per year, and an additional $10 / square foot\"\n",
      "    *   The student wrote: \"100,000 + 100x\"\n",
      "    *   The \"additional $10 / square foot\" should be `10x`, not `100x`. The student incorrectly used 100 instead of 10 for the per-square-foot maintenance cost.\n",
      "\n",
      "**Corrected Solution:**\n",
      "\n",
      "Let x be the size of the installation in square feet.\n",
      "\n",
      "*   **Land cost:** 100x\n",
      "*   **Solar panel cost:** 250x\n",
      "*   **Maintenance cost:** 100,000 + 10x\n",
      "\n",
      "**Total cost for the first year:**\n",
      "100x + 250x + 100,000 + 10x\n",
      "= (100 + 250 + 10)x + 100,000\n",
      "= **360x + 100,000**\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine if the student's solution is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost\n",
    "me a flat $100k per year, and an additional $10 / square\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978f672f-b568-438b-8632-5395edfa3198",
   "metadata": {},
   "source": [
    "<mark>Gemini was better at spotting the incorrect student solution, I guess it already forces itself to use more time to reason through the problem first.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3b4ea4a-e640-466d-b6ac-3e567f1b5c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The student's solution is **incorrect**.\n",
       "\n",
       "Here's a breakdown of the error:\n",
       "\n",
       "1.  **Land cost:** Correct (100x)\n",
       "2.  **Solar panel cost:** Correct (250x)\n",
       "3.  **Maintenance cost:** This is where the error occurs.\n",
       "    *   The problem states: \"flat $100k per year, and an additional $10 / square foot\"\n",
       "    *   The student wrote: \"100,000 + 100x\"\n",
       "    *   The \"additional $10 / square foot\" should be `10x`, not `100x`. The student incorrectly used 100 instead of 10 for the per-square-foot maintenance cost.\n",
       "\n",
       "**Corrected Solution:**\n",
       "\n",
       "Let x be the size of the installation in square feet.\n",
       "\n",
       "*   **Land cost:** 100x\n",
       "*   **Solar panel cost:** 250x\n",
       "*   **Maintenance cost:** 100,000 + 10x\n",
       "\n",
       "**Total cost for the first year:**\n",
       "100x + 250x + 100,000 + 10x\n",
       "= (100 + 250 + 10)x + 100,000\n",
       "= **360x + 100,000**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex, HTML, JSON\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322ebd9-0f8a-43aa-97fe-5eac70cdcc6a",
   "metadata": {},
   "source": [
    "#### Note that the student's solution is actually not correct.\n",
    "#### We can fix this by instructing the model to work out its own solution first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "703f7003",
   "metadata": {
    "height": 1014,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Actual solution:\n",
       "Let `x` be the size of the installation in square feet.\n",
       "\n",
       "The total cost for the first year includes:\n",
       "1.  **Land cost:** This is a one-time capital cost.\n",
       "    Cost = $100/square foot * `x` square feet = `100x`\n",
       "2.  **Solar panel cost:** This is a one-time capital cost.\n",
       "    Cost = $250/square foot * `x` square feet = `250x`\n",
       "3.  **Maintenance cost for the first year:** This is an annual operational cost.\n",
       "    Flat fee = $100,000 per year\n",
       "    Additional cost = $10/square foot * `x` square feet = `10x`\n",
       "    Total maintenance cost for the first year = `100,000 + 10x`\n",
       "\n",
       "Total cost for the first year of operations = (Land cost) + (Solar panel cost) + (First year's maintenance cost)\n",
       "Total cost = `100x + 250x + (100,000 + 10x)`\n",
       "Total cost = `100x + 250x + 10x + 100,000`\n",
       "Total cost = `(100 + 250 + 10)x + 100,000`\n",
       "Total cost = `360x + 100,000`\n",
       "\n",
       "Is the student's solution the same as actual solution just calculated:\n",
       "no\n",
       "\n",
       "Student grade:\n",
       "incorrect\n",
       "\n",
       "Discrepancy between solutions:\n",
       "The student made an error in calculating the maintenance cost. The problem states \"an additional $10 / square foot\" for maintenance, but the student used `$100 / square foot` in their calculation, resulting in `100x` for the variable part of the maintenance cost instead of the correct `10x`. This led to an incorrect coefficient for `x` in the final total cost function."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem including the final total. \n",
    "- Then compare your solution to the student's solution\n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "Discrepancy between solutions:\n",
    "```\n",
    "if the student's solution is incorrect explain where and why\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost me \n",
    "a flat $100k per year, and an additional $10 / square foot\n",
    "What is the total cost for the first year of operations as \n",
    "a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "```\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "```\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a207eab-a1b1-47a5-b913-fe38086123d0",
   "metadata": {},
   "source": [
    "## Model Limitations: Hallucinations\n",
    "- Boie is a real company, the product name is not real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81c80919",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you've come across a very **humorous and definitely fictional** product name!\n",
      "\n",
      "There is no actual toothbrush called the \"Tooth Destroyer Hardcore EnamelGrinder UltraSlow Smart Toothbrush\" by Boie (or anyone else, for that matter!). The name is clearly designed to be an ironic and exaggerated take on toothbrush marketing, especially with terms like \"Tooth Destroyer\" and \"EnamelGrinder,\" which are the *opposite* of what a toothbrush aims to do, and \"UltraSlow\" which contradicts common electric toothbrush features.\n",
      "\n",
      "**However, Boie is a real company!**\n",
      "\n",
      "**Boie USA** (often just Boie) is known for making innovative toothbrushes, primarily recognized for:\n",
      "\n",
      "1.  **Silicone Bristles:** Unlike traditional nylon bristles, Boie toothbrushes feature soft, hypoallergenic silicone bristles. This design is touted for being:\n",
      "    *   **Gentle on gums and enamel:** They aim for effective cleaning without being abrasive.\n",
      "    *   **Hygienic:** Silicone is less porous than nylon, which is claimed to resist bacteria buildup more effectively.\n",
      "    *   **Durable:** The bristles last longer than traditional ones.\n",
      "2.  **Minimalist Design:** Their toothbrushes often have a sleek, modern, and simple aesthetic.\n",
      "3.  **Sustainable Approach:** They sometimes emphasize the longevity of their brushes and reducing plastic waste.\n",
      "4.  **Sonic Technology:** They do offer \"sonic\" versions of their silicone toothbrushes, providing vibrations to enhance cleaning.\n",
      "\n",
      "So, while Boie makes toothbrushes that are often gentle, hygienic, and sometimes \"smart\" in their material science, they would never brand a product with terms implying destruction or abrasion like \"Tooth Destroyer\" or \"EnamelGrinder.\" Their actual products are designed to be quite the opposite!\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about Tooth Destroyer Hardcore EnamelGrinder UltraSlow Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82838d7-d8d8-477f-a59b-35477a3d3fb4",
   "metadata": {},
   "source": [
    "<mark>Caught the satire, perhaps it performed an internet search for the product also. Something to check later.</mark>\n",
    "Let's try something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89800595-c20b-4fe2-bb03-515faffbf455",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems there might be a slight mix-up in the product name or brand you're recalling!\n",
      "\n",
      "**I cannot find any product called the \"AeroGlide UltraSlim Smart Toothbrush\" specifically from the brand Boie.**\n",
      "\n",
      "**Boie (often known as Boie USA)** is actually famous for its **manual toothbrushes**, which are known for their incredibly soft, rubber-like bristles (made from medical-grade thermoplastic elastomer) and minimalist design. They are designed for gentle, effective cleaning without any electronic or \"smart\" features.\n",
      "\n",
      "Their flagship product is simply called the **Boie USA Toothbrush** (or similar variations), and it's a completely manual brush. It doesn't have app connectivity, sonic vibrations, or the kind of \"smart\" features implied by \"Smart Toothbrush.\"\n",
      "\n",
      "**Could you be thinking of a different brand, or perhaps a different product name?**\n",
      "\n",
      "Brands like **Philips Sonicare, Oral-B, Quip, Burst, or Oclean** are well-known for offering \"smart\" electric toothbrushes that often feature slim designs, app connectivity, various brushing modes, and advanced technology.\n",
      "\n",
      "If you're interested in the **Boie manual toothbrush**, I can certainly tell you more about its unique features!\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me about AeroGlide UltraSlim Smart Toothbrush by Boie\n",
    "\"\"\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683eab0-c177-4240-a692-6c18e025bf2d",
   "metadata": {},
   "source": [
    "<mark>Gemini shows it checks online for proof, this could fail when there is also misinformation to be found out there.</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea88a6e-0141-4296-a73b-6b2282fe0de6",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c0c68aeb-194e-48e4-9c31-2ca60d80b194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Prompt Development Process\n",
      "\n",
      "**Why:** Developing effective prompts is an iterative process, focusing on refining ideas rather than achieving perfection on the first try.\n",
      "\n",
      "**How:** \n",
      "1. Start with an idea\n",
      "2. Write a prompt\n",
      "3. Run it\n",
      "4. Analyze the result\n",
      "5. Refine the prompt based on feedback\n",
      "6. Iterate until achieving the desired outcome\n",
      "\n",
      "**What:** The lesson demonstrates the process of developing prompts for applications using large language models, emphasizing the importance of clarity, specificity, and iteration in prompt engineering.\n",
      "\n",
      "## Cheatsheet:\n",
      "- Start with an idea for the task you want to achieve.\n",
      "  - *Reasoning:* Clear objectives lead to focused prompts.\n",
      "  - *Example:* Define the goal of summarizing a fact sheet for a chair.\n",
      "- Write a clear and specific prompt.\n",
      "  - *Reasoning:* Specific instructions guide the model effectively.\n",
      "  - *Example:* Task the model with creating a product description based on the fact sheet.\n",
      "- Analyze the result and refine the prompt iteratively.\n",
      "  - *Reasoning:* Feedback helps improve the prompt for better outcomes.\n",
      "  - *Example:* Adjust the prompt to limit the word count for a more concise description.\n",
      "\n",
      "## Quotes:\n",
      "- \"Developing a prompt is an iterative process.\"\n",
      "- \"The key to being an effective prompt engineer is having a good process.\"\n",
      "- \"Prompts are effective when they are tailored to your application.\"\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
